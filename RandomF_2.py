import pandas as pd
import os
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import warnings
# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

def train_iris_model(file_path):
    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ (å·¥ç¨‹æœ€ä½³å®è·µï¼šé˜²å¾¡æ€§ç¼–ç¨‹)
    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯ï¼šåœ¨å½“å‰ç›®å½•ä¸‹æ‰¾ä¸åˆ°æ–‡ä»¶ '{file_path}'ã€‚")
        print("è¯·ç¡®ä¿å°†æ•°æ®ä¿å­˜ä¸º 'iris.data' å¹¶ä¸è„šæœ¬æ”¾åœ¨åŒä¸€ç›®å½•ï¼Œæˆ–è€…æä¾›ç»å¯¹è·¯å¾„ã€‚")
        return
    try:
        print(f"æ­£åœ¨ä» {file_path} åŠ è½½æ•°æ®...")

        # å®šä¹‰åˆ—å
        column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']

        # è¯»å–æœ¬åœ°æ–‡ä»¶
        # header=None è¡¨ç¤ºæ–‡ä»¶ä¸­æ²¡æœ‰åˆ—åè¡Œ
        df = pd.read_csv(file_path, header=None, names=column_names)

        print(f"æ•°æ®åŠ è½½æˆåŠŸã€‚å…± {len(df)} æ¡è®°å½•ã€‚")

        # 2. æ•°æ®é›†åˆ’åˆ†
        X = df.drop('class', axis=1)
        y = df['class']

        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # 3. æ¨¡å‹è®­ç»ƒ
        print("æ­£åœ¨è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹...")
        rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
        rf_classifier.fit(X_train, y_train)

        # 4. é¢„æµ‹ä¸è¯„ä¼°
        y_pred = rf_classifier.predict(X_test)

        print("-" * 30)
        print(f"å‡†ç¡®ç‡ (Accuracy): {accuracy_score(y_test, y_pred):.4f}")
        print("\nåˆ†ç±»æŠ¥å‘Š (Classification Report):")
        print(classification_report(y_test, y_pred))

        # 5. ç‰¹å¾é‡è¦æ€§
        print("-" * 30)
        print("ç‰¹å¾é‡è¦æ€§åˆ†æ:")
        importances = rf_classifier.feature_importances_
        feature_imp_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})
        print(feature_imp_df.sort_values(by='Importance', ascending=False))
        print("-" * 30)

        # 6. é™å®šèŒƒå›´å†…éšæœºç”Ÿæˆä¸€æ¡æ–°æ•°æ®è¿›è¡Œé¢„æµ‹
        # ---------------------------------------------------------
        print("æ­£åœ¨ç”Ÿæˆéšæœºæ ·æœ¬è¿›è¡Œæµ‹è¯•...")

        # è·å–æ¯ä¸ªç‰¹å¾çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ï¼Œä½œä¸ºéšæœºç”Ÿæˆçš„è¾¹ç•Œ
        min_values = X.min()
        max_values = X.max()
        print(f"\nç‰¹å¾å–å€¼èŒƒå›´å‚è€ƒ (Min - Max):")
        for col in X.columns:
            print(f"  {col}: {min_values[col]:.1f} - {max_values[col]:.1f}")

        # ä½¿ç”¨ numpy ç”Ÿæˆéšæœºæ•°æ®
        # np.random.uniform ä¼šåœ¨ [min, max] ä¹‹é—´ç”Ÿæˆè¿ç»­å‡åŒ€åˆ†å¸ƒçš„éšæœºæ•°
        random_features = np.random.uniform(low=min_values, high=max_values)

        # å°† Series è½¬æ¢ä¸º numpy æ•°ç»„å¹¶è°ƒæ•´å½¢çŠ¶ä¸º (1, 4) ä»¥ç¬¦åˆ sklearn çš„è¾“å…¥è¦æ±‚
        new_sample_reshaped = random_features.reshape(1, -1)

        # åˆ›å»ºä¸€ä¸ª DataFrame ç”¨äºå±•ç¤ºï¼ŒåŒ…å«åˆ—åï¼Œæ–¹ä¾¿æŸ¥çœ‹
        new_sample_df = pd.DataFrame(new_sample_reshaped, columns=X.columns)
        print("\nç”Ÿæˆçš„éšæœºæ ·æœ¬æ•°æ®:")
        print(new_sample_df.round(2).to_string(index=False))  # ä¿ç•™ä¸¤ä½å°æ•°æ‰“å°

        # è¿›è¡Œé¢„æµ‹
        prediction = rf_classifier.predict(new_sample_reshaped)
        print("-" * 30)
        print(f"ğŸŒ² æ¨¡å‹é¢„æµ‹åˆ†ç±»ç»“æœ: {prediction[0]}")
    except Exception as e:
        print(f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")


if __name__ == "__main__":
    # æŒ‡å®šæœ¬åœ°æ–‡ä»¶è·¯å¾„
    local_filename = 'iris.csv'

    train_iris_model(local_filename)